\documentclass[sigconf]{acmart}

\usepackage{booktabs} % For formal tables

\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\newcommand\TODO[1]{\textcolor{red}{#1}}
\newcommand{\lucenequery}[1]{\vspace{1mm}\texttt{#1}\vspace{1mm}}
% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\acmDOI{10.475/123_4}

% ISBN
\acmISBN{123-4567-24-567/08/06}

%Conference
\acmConference[KDD'17]{ACM KDD conference}{August 13--17, 2017}{Halifax, Nova Scotia, Canada.} 
\acmYear{2017}
\copyrightyear{2017}

\acmPrice{15.00}


\begin{document}
\title{Latency Reduction via Decision Tree Based Query Construction}

\author{Aman Grover}
\affiliation{%
  \institution{LinkedIn Corporation}
}
\email{agrover@linkedin.com}


\author{Dhruv Arya}
\affiliation{%
  \institution{LinkedIn Corporation}
}
\email{darya@linkedin.com}


\author{Ganesh Venkataraman}
\affiliation{%
  \institution{LinkedIn Corporation}
}
\email{ghvenkat@linkedin.com}


\begin{abstract}
LinkedIn as a professional network serves the career needs of 450 Million plus members. 
The task of job recommendation system is to find the suitable job among a corpus of several million jobs and serve this in real time under tight latency constraints. 
Job search involves finding suitable job listings given a user, query and
context.  Typical scoring function for both search and recommendations 
involves evaluating a function that matches various fields in the job description 
with various fields in the member profile.
This in turn translates to evaluating a function with several thousands of features to get the right ranking. 
In recommendations, evaluating all the jobs in the corpus for all members is not possible given the latency constraints. 
On the other hand, reducing the candidate set could 
potentially involve loss of relevant jobs. 
We present a way to model the underlying complex ranking function via decision
trees. The branches within the decision trees are query clauses and hence the
decision trees can be mapped on to real time queries. 
%We present a decision tree based approach to query construction. 
%This work provides a novel way of improving the candidate jobs for the job seeker without hurting the overall relevance of the product. 
%We propose a novel way to model the underlying complex ranking function with a
%decision tree. The variable within the branching of the decision tree would be
%candidate query clauses. 
We developed an offline framework which
evaluates the quality of the decision tree with respect to latency and recall.
We tested the approach on job search and recommendations on LinkedIn and A/B tests show significant improvements in member engagement and latency. 
Our techniques helped reduce job search latency by over {\bf 67\%} and our
recommendations latency by over {\bf 55\%}. Our techniques
show {\bf 3.5\%} improvement in applications from job recommendations
primarily due to reduced timeouts from upstream services.
{\bf As of writing the approach powers all of job search and recommendations on LinkedIn.} 
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
<concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Information retrieval~Document filtering</concept_desc>
  <concept_desc>Recommender Systems~Query Reformulation</concept_desc>
  <concept_desc>Machine Learning~Decision Trees</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

% We no longer use \terms command
%\terms{Theory}

\keywords{Information Retrieval, Personalized Search, Recommender Systems}


\maketitle
\input{introduction.tex}
\input{related-work.tex}

\section{Problem Formulation}
Let
\begin{itemize}
    \item $EQ$ represent the explicit user query. In search $EQ$ represents the
        search term and in recommendations $EQ$ is empty.
    \item $U$ represent set of user attributes in the profile. Example -
        current company, current title etc.
    \item $C$ represent the context. This may include past job searches,
        job applies, jobs views etc.
    \item $D(q)$ represents the set of document retrieved from inverted index
        for a given query $q$. $|D(q)|$ represents it's cardinality.
    %\item $M$ represent the set of all documents that match the users explicit
    %    query $EQ$. In recommender systems, $M$
    %    could include all documents in the index. In search, it could be more
    %    restrictive in the presence of an explicit query.
    \item $k$ represent the top documents required to be shown to the user and
        $M$ represent the total number of documents that match the query.
        Typically $k << |M|$.
    \item $R_f(d, k)$ represent the underlying ranking function which generates
        top k documents from document set $d$.  

\end{itemize}
The ranking function takes a (user, query, document) tuple and converts it into a score. Our
ranking function is highly personalized using per member and per job
coefficients. This work doesn't touch the ranking function but modifies the query. 
Interested reader may refer to ~\cite{zhang2016glmix, liget} for more details. The
objective of this work is to come up with a constructed query $CQ$
such that the number of documents retrieved is minimized while the top $k$ documents are not
lost due to restricted query construction. More formally:

\begin{equation} \label{eq:problem-formulation}
    \begin{aligned}
        \textrm{Given} \quad R_f \\
    CQ = g(U, EQ, C) \\
        \textrm{minimize} \quad |D(CQ)| \\
        s. t. \quad  R_f(D(CQ), k) = R_f(D(EQ), k)
    \end{aligned}
\end{equation}

Assume that we need the top 25 jobs and explicit query matched 1 Million jobs.
This implies that we need to rank 1 Million jobs without query construction.
Suppose the constructed query matches 10K jobs, 
as long as the top 25 jobs (out of the 1 Million jobs that matched the original query) are
still part of the 10K retrieved jobs, we are have no loss of recall and
significant reduction in latency.
We come up with a decision tree based technique which will automatically learn
the function $g$ to construct the query while trying to optimize the problem
stated in equation~\ref{eq:problem-formulation}.


\input{system-architecture.tex}

\begin{figure}
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{offline-indexing.png}
\caption{Offline Indexing}
\label{fig:offline-indexing}
\end{figure}




\input{decision-trees2.tex}

\input{experiments.tex}
\input{deployment-lessons.tex}
\input{conclusions.tex}
\input{ack.tex}


\bibliographystyle{abbrv}
\bibliography{sigproc} 

\end{document}
